[INFO] No checkpoint found at None. Starting from scratch.
Start_epoch: 0, start_step: 0
Starting epoch 1/100...
Epoch 1:   0%|â–Š                                                                                                                                                                                           | 356/84952 [08:01<26:37:38,  1.13s/it, Loss=25]Traceback (most recent call last):
  File "/workspace/rewas/./train_miil.py", line 347, in <module>
    main(args)
  File "/workspace/rewas/./train_miil.py", line 209, in main
    pred_cam = phi(hint.float(), attn_mask=attn_mask_flat).squeeze(2)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py", line 191, in forward
    return self.module(*inputs[0], **module_kwargs[0])
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/rewas/encoder/phi.py", line 47, in forward
    x = self.hint_blocks(x, attn_mask)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/rewas/encoder/transformer.py", line 277, in forward
    tokens = blk(tokens, attn_mask=attn_mask)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/rewas/encoder/transformer.py", line 161, in forward
    x = x + self.drop_path(self.attn(self.norm_1(x), attn_mask))
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/rewas/encoder/transformer.py", line 96, in forward
    return super().forward(x, x, x, need_weights=False, key_padding_mask=attn_mask)[0]
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1368, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/root/miniconda3/envs/rewas/lib/python3.10/site-packages/torch/nn/functional.py", line 6278, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
KeyboardInterrupt
